{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $k$-nearest neighors\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Nathan Karst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](https://www.dropbox.com/s/acoelg7u7acljii/knn_example_0.png?raw=1)\n",
    "\n",
    "* Imagine we have three values of our target: red triangle, blue square, and green circle. \n",
    "\n",
    "\n",
    "* Here, we have just two predictors, $X_1$ and $X_2$. \n",
    "\n",
    "\n",
    "* Notice that both have a range of [0,1]. We'll talk about why this is later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](https://www.dropbox.com/s/5vdx9ykam4mj2vn/knn_example_1.png?raw=1)\n",
    "\n",
    "* Imagine we receive a new record represented by the black triangle. \n",
    "\n",
    "\n",
    "* How should we classify this new data point? It makes sense to compare the new point to the most similar known points.\n",
    "\n",
    "\n",
    "* It appears to be in the red region, but the single point most similar to it is blue.\n",
    "\n",
    "\n",
    "* How do we resolve this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www.dropbox.com/s/5vdx9ykam4mj2vn/knn_example_1.png?raw=1)\n",
    "\n",
    "* In $k$-nearest neighbors, we make the $k$ closest points to our new, unknown data point \"vote\" on what our prediction should be.\n",
    "\n",
    "\n",
    "* Imagine $k = 1$. The closest neighbor to our new point is blue, and so our prediction would be blue.\n",
    "\n",
    "\n",
    "* Imagine $k = 3$. Of the $k = 3$ closest neighbors, 2 are red, and 1 is blue, so our prediction would be red. \n",
    "\n",
    "\n",
    "* Imagine $k = 5$. Of the $k = 5$ closest neighbors, 3 are red, and 2 are blue, so our prediction would be red. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](https://www.dropbox.com/s/tmnpkpx1c6hm15h/knn_example_2.png?raw=1)\n",
    "\n",
    "* Now imagine we get a new unclassified point, again represented by the black triangle.\n",
    "\n",
    "\n",
    "\n",
    "* What are the predictions when $k = 1, 3, 5, 7$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](https://www.dropbox.com/s/rxb2n79ry6ox28a/knn_example_3.png?raw=1)\n",
    "\n",
    "\n",
    "* Note that $k$-nearest neighbors will make a prediction even when there are not many neighbors nearby. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* When we're talking about \"nearest\" here, we're really referring to Euclidean distance. \n",
    "\n",
    "\n",
    "* The distance between two points in the plane $(x_1, y_1)$ and $(x_2, y_2)$ is\n",
    "<br>\n",
    "<br>\n",
    "$$d = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}.$$\n",
    "<br>\n",
    "* This generalizes really nicely to cases where we have more than two predictors.\n",
    "\n",
    "\n",
    "* The distance between two points $(u_1, u_2, \\ldots, u_p)$ and $(v_1, v_2, \\ldots, v_p)$ is\n",
    "<br>\n",
    "<br>\n",
    "$$d = \\sqrt{(u_1 - v_1)^2 + (u_2 - v_2)^2 + \\ldots + (u_p - v_p)^2}.$$ \n",
    "<br>\n",
    "* **Note: talking about distance only makes sense when we have numeric inputs!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example\n",
    "\n",
    "\n",
    "* Let's look again at `BostonHousing`.\n",
    "\n",
    "\n",
    "* This time around, we're going to try to predict whether a neighborhood's median home value is above $30,000 or not. This is captured in the variable `CAT. MEDV`. \n",
    "\n",
    "\n",
    "* But why use a categorical target instead of a numerical one? Complexity and cost are higher for numerical variables - it takes less time and money to figure out whether a neighborhood has high or low value homes than it does to figure out exactly what that median value is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setup \n",
    "\n",
    "* As always, we'll need to load some packages before we get started. \n",
    "\n",
    "\n",
    "* Most of these we've used before. \n",
    "\n",
    "\n",
    "* The exceptions are\n",
    "    * `from sklearn import neighbors`: this is where the actual knn function we'll be using lives\n",
    "    * `import numpy as np`: `numpy` (short for \"numerical python\") is a really common library to teach up with `pandas` and `sklearn`. We'll use this to help us select only the numerical columns in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import BabsonAnalytics\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Load and manage\n",
    "\n",
    "* Loading is the same as always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/BostonHousing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* To manage, we first should make all necessary numeric to categoric conversions.\n",
    "\n",
    "\n",
    "* Notice that since we're predicting a categorical version of median value, we can't really use the *actual* median value as a predictor - this has to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  LSTAT  \\\n",
       "0  0.00632  18.0   2.31  0.538  6.575  65.2  4.0900    1  296     15.3   4.98   \n",
       "1  0.02731   0.0   7.07  0.469  6.421  78.9  4.9671    2  242     17.8   9.14   \n",
       "2  0.02729   0.0   7.07  0.469  7.185  61.1  4.9671    2  242     17.8   4.03   \n",
       "3  0.03237   0.0   2.18  0.458  6.998  45.8  6.0622    3  222     18.7   2.94   \n",
       "4  0.06905   0.0   2.18  0.458  7.147  54.2  6.0622    3  222     18.7   5.33   \n",
       "\n",
       "   CAT. MEDV  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CHAS = df.CHAS.astype(\"category\")\n",
    "df.drop('MEDV',axis=1,inplace=True)\n",
    "\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Partition\n",
    "\n",
    "* This works the same as it did with linear models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.8)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "trainTarget = train.pop('CAT. MEDV')\n",
    "testTarget = test.pop('CAT. MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Build\n",
    "\n",
    "* As with linear models, with knn we must\n",
    "    * make an empty model\n",
    "    * fit the empty model to the training data\n",
    "    \n",
    "    \n",
    "* Let's use $k = 15$ for now. (We'll talk about how we might think about finding the \"best\" value of $k$ later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors=15)\n",
    "model.fit(train,trainTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predict\n",
    "\n",
    "* Predicting works *exactly* the same here as it did in linear models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "\n",
    "* When predicting categorical targets, there is in general no notion of being \"close\" - we either get the prediction right or wrong - and our notions of model performance need to reflect this.\n",
    "\n",
    "\n",
    "* The **error rate** of a set of predictions is simply the number of incorrect predictions divided by the total number total predictions:\n",
    "<br>\n",
    "<br>\n",
    "$$\\mbox{error rate} = \\frac{\\#(\\mbox{predictions} \\neq \\mbox{observations})}{\\#(\\mbox{predictions})}$$\n",
    "<br>\n",
    "* In Python,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate:  0.128712871287\n"
     ]
    }
   ],
   "source": [
    "correct = predictions == testTarget\n",
    "incorrect = predictions != testTarget\n",
    "error_rate = sum(predictions != testTarget)/len(predictions)\n",
    "print('Error rate: ', error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Benchmark error rate\n",
    "\n",
    "* Is this error rate good or bad? \n",
    "\n",
    "\n",
    "* We need to compare any observed error rate to *something* in order to figure out whether it was worth collecting the data, building the model, and predicting the target at all!\n",
    "\n",
    "\n",
    "* The **benchmark error rate** for categorical targets is the error rate we would have achieved if we had simply used the most common target value in the training data set as our prediction for every record in test.\n",
    "\n",
    "\n",
    "* For instance, if more neighborhoods were low value in the training, we would predict that *every* neighborhood in the test as low value. We would be right part of the time and wrong part of the time. The fraction of the total number of predictions we got wrong would be our benchmark error rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate:  0.128712871287\n",
      "Benchmark:  0.158415841584\n"
     ]
    }
   ],
   "source": [
    "bench_rate = BabsonAnalytics.benchmarkErrorRate(trainTarget,testTarget)\n",
    "print('Error rate: ', error_rate)\n",
    "print('Benchmark: ',bench_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Since our error rate is better than the benchmark, we conclude that our model is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of errors\n",
    "\n",
    "* In practice, not all errors are the same - some can be much more expensive than others.\n",
    "\n",
    "\n",
    "* We can start to get a handle on the types of errors we're making by looking at the **confusion matrix** associated with our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Observations</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Observations   0   1\n",
       "Predictions         \n",
       "0             84  12\n",
       "1              1   4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = BabsonAnalytics.confusionMatrix(predictions,testTarget)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117a638d0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAF2CAYAAACYrmpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a62160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# False positives and false negatives\n",
    "\n",
    "* A false positive occurs when we predict 1 but observe 0 - we falsely think the positive outcome would happen.\n",
    "\n",
    "\n",
    "* In the example of `BostonHousing`, a false positive would mean that we thought a neighborhood would have high value homes (target value 1) when in fact it had low value homes (target value 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Observations</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Observations   0   1\n",
       "Predictions         \n",
       "0             84  12\n",
       "1              1   4"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* With these predictions, there are 2 false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# False positives and false negatives\n",
    "\n",
    "* A false negative occurs when we predict 1 but observe 0 - we falsely think the negative outcome would happen.\n",
    "\n",
    "\n",
    "* In the example of `BostonHousing`, a false negative would mean that we thought a neighborhood would have low value (target value 0) homes when in fact it had high value homes (target value 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Observations</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Observations   0   1\n",
       "Predictions         \n",
       "0             84  12\n",
       "1              1   4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* With these predictions, there are 13 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sensitivity and specificity\n",
    "\n",
    "* The sensitivity of our predictions is the percentage of observations of target value 1 that we predict correctly. \n",
    "\n",
    "\n",
    "* In the example of `BostonHousing`, sensitivity is the percentage of high value homes that we predict correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Observations</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Observations   0   1\n",
       "Predictions         \n",
       "0             84  12\n",
       "1              1   4"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* With these predictions, the sensitivity is $4/17 \\approx 24\\%$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sensitivity and specificity\n",
    "\n",
    "* The specificity of our predictions is the percentage of observations of target value 0 that we predict correctly. \n",
    "\n",
    "\n",
    "* In the example of `BostonHousing`, sensitivity is the percentage of low value homes that we predict correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Observations</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Observations   0   1\n",
       "Predictions         \n",
       "0             84  12\n",
       "1              1   4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* With these predictions, the specificity is $82/84 \\approx 98\\%$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# False positive/negatives vs. sensitivity/specificity\n",
    "\n",
    "* Imagine you're getting a medical test. A value of 1 indicates that the test believes you have the disease.\n",
    "\n",
    "\n",
    "* From the patient's perspective:\n",
    "    * \"What are the chances the test thinks I don't have the disease but I actually do?\" (**false negative rate**)\n",
    "    * \"What are the chances the test thinks I have the disease but I actually don't?\" (**false positive rate**)\n",
    "    \n",
    "    \n",
    "* From the doctor's perspective:\n",
    "    * \"What are the chances the test detects the disease given the patient has the disease?\" (**sensitivity**)\n",
    "    * \"What are the chances the test does not detect the disease given the patient does not have the disease?\" (**specificity**)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization and standardization\n",
    "\n",
    "\n",
    "* We can run into problems when using distances across different ranges to make predictions.\n",
    "\n",
    "\n",
    "* Imagine a case in which we have just two predictors: one with range [0,1] and the other with [0,10]. \n",
    "\n",
    "\n",
    "* We might plot two data points like this:\n",
    "![alt text](https://www.dropbox.com/s/tv99m1gm7s3uzrh/distance_unscaled.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization and standardization\n",
    "\n",
    "* But if we were to plot everything to scale, the two points would look something like this:\n",
    "\n",
    "![alt text](https://www.dropbox.com/s/dxns8lz8uk5502u/distance_scaled.png?raw=1)\n",
    "\n",
    "\n",
    "* The distance between the two data points is almost completely determined by their separation in the horizontal direction, that is, by their difference in the variable with the larger range.\n",
    "\n",
    "\n",
    "* In order to give every variable a chance to contribute to our predictions, we some how need to equalize their strengths.\n",
    "\n",
    "\n",
    "* There are two many ways to do this: normalization and standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization and standardization\n",
    "\n",
    "* In normalization, we put every variable on the same scale, say [0,1]:\n",
    "\n",
    "$$\\tilde{X} = \\frac{X - \\min(X)}{\\max(X) - \\min(X)}.$$\n",
    "\n",
    "* A value of $\\tilde{X} = 0$ corresponds to $X$ being at its minimum; a value of $\\tilde{X} = 1$ corresponds to $X$ being at its maximum.\n",
    "\n",
    "\n",
    "\n",
    "* In standardization, we convert each observation into a $t$-score:\n",
    "\n",
    "$$\\tilde{X} = \\frac{X - \\bar{X}}{s_X},$$\n",
    "\n",
    "where $\\bar{X}$ is the sample mean and $s_X$ is the sample standard deviation.\n",
    "\n",
    "\n",
    "\n",
    "* If $\\tilde{X} = -1$, then $X$ was one standard deviation below the mean. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization and standardization\n",
    "\n",
    "* We can implement both normalization and standardization easily using `pandas`.\n",
    "\n",
    "\n",
    "* **Note: we do not want to normalize/standardize the target, so we perform the operation to the train and test data frames from which the target has been removed!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_normalized = (train - train.min())/(train.max() - train.min())\n",
    "test_normalized = (test - test.min())/(test.max() - test.min())\n",
    "\n",
    "train_standardized = (train - train.mean())/train.std()\n",
    "test_standardized = (test - test.mean())/test.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization and standardization\n",
    "\n",
    "* We could also perform the same operations using `sklearn`.\n",
    "\n",
    "\n",
    "* (This is a little less clear, but can be more powerful when using `sklearn`'s `Pipeline` feature.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "normalizer = preprocessing.MinMaxScaler()\n",
    "train_normalized = normalizer.fit_transform(train)\n",
    "test_normalized = normalizer.fit_transform(test)\n",
    "\n",
    "standardizer = preprocessing.StandardScaler()\n",
    "train_standardized = standardizer.fit_transform(train)\n",
    "test_standardized = standardizer.fit_transform(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization and standardization\n",
    "\n",
    "* After we have our transformed data, we can build our models as we normally would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate (normalized):  0.0891089108911\n"
     ]
    }
   ],
   "source": [
    "model_normalized = neighbors.KNeighborsClassifier(n_neighbors=15)\n",
    "model_normalized.fit(train_normalized,trainTarget)\n",
    "predictions_normalized = model_normalized.predict(test_normalized)\n",
    "\n",
    "error_rate_normalized = sum(predictions_normalized != testTarget)/len(predictions_normalized)\n",
    "print('Error rate (normalized): ', error_rate_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate (standardized):  0.148514851485\n"
     ]
    }
   ],
   "source": [
    "model_standardized = neighbors.KNeighborsClassifier(n_neighbors=15)\n",
    "model_standardized.fit(train_standardized,trainTarget)\n",
    "predictions_standardized = model_scaled.predict(test_standardized)\n",
    "\n",
    "error_rate_standardized = sum(predictions_standardized != testTarget)/len(predictions_standardized)\n",
    "print('Error rate (standardized): ', error_rate_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
